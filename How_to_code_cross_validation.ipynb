{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "Cross-validation (CV) is an important step in the whole predictive modelling process. Luckily it is not the hardest bit to code. Let's have a look at the basic setup below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The dataset and classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "First, let's introduce the dataset and divide it into training and test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "X,y = make_classification(n_samples=1000, n_features=10,\n",
    "                               n_informative=2, n_redundant=0, n_repeated=0,\n",
    "                               n_classes=2,\n",
    "                               n_clusters_per_class=1,\n",
    "                               weights=(0.7,0.3),\n",
    "                               class_sep=0.99, random_state=14)\n",
    "\n",
    "\n",
    "# You already know about training and test splits:\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "To apply cross-validation, we need a classifier as well. Let's use logistic regression for now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "classifier = LogisticRegression(solver='liblinear')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "Here, we introduce the classifier into the CV process. It really is a process, e.g., for 10-Fold CV, we have a 10-step process. The classifier is embedded into the whole process, and used on the 10 training sets that are generated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy scores: [0.97857143 1.         0.97857143 0.99285714 0.99285714]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(classifier, X_train, y_train, cv=5)\n",
    "print('Accuracy scores: '+str(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "What have we just calculated? In this case, the accuracy. Let's now add some other metrics as well, e.g., the AUC:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.         0.99443414 1.         1.         0.98979592 1.\n",
      " 1.         1.         0.97123016 1.        ]\n"
     ]
    }
   ],
   "source": [
    "outcomes = cross_val_score(classifier, X_train, y_train, cv=10, scoring='roc_auc')\n",
    "print(outcomes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "If you are interested in multiple metrics at the same time, another function is more appropriate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit_time value: [0.00166774 0.00152278 0.00139213 0.00149798 0.00143528 0.0014863\n",
      " 0.00129914 0.00148988 0.00146437 0.00148535]\n",
      "score_time value: [0.00180101 0.00159717 0.00159097 0.00157166 0.00154829 0.00159287\n",
      " 0.001544   0.00159526 0.00157309 0.00155425]\n",
      "test_roc_auc value: [1.         0.99443414 1.         1.         0.98979592 1.\n",
      " 1.         1.         0.97123016 1.        ]\n",
      "train_roc_auc value: [0.99681514 0.9972073  0.99685079 0.99691021 0.99739744 0.99699214\n",
      " 0.99693317 0.99672085 0.99949279 0.99673264]\n",
      "test_accuracy value: [0.95774648 0.98591549 1.         1.         0.97183099 1.\n",
      " 1.         0.98550725 0.98550725 1.        ]\n",
      "train_accuracy value: [0.99205087 0.99205087 0.98887122 0.98887122 0.9936407  0.9889065\n",
      " 0.9889065  0.99049128 0.99049128 0.9889065 ]\n",
      "test_precision value: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "train_precision value: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "# metrics you want to have computed\n",
    "metrics = ['roc_auc','accuracy','precision']\n",
    "\n",
    "# By default, we should not really care about the training scores. To show them, we add the extra return_train_score parameter\n",
    "outcomes = cross_validate(classifier, X_train, y_train, scoring=metrics, cv=10, return_train_score=True)\n",
    "for metric in outcomes.keys():\n",
    "    print(metric+\" value: \"+str(outcomes[metric]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "Now, the outcome is a dictionary with the different metrics per fold for both the training and test set (note that, since we have set aside a separate test set, this is our validation set in this case)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up a pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "Remember when we talked about training, validation and test sets, we mentioned that the pre-processing (e.g., replacing missing values, transformations, over- and under-sampling, etc.) should be performed on the training and test set separately to avoid any bias? That is, the same transformation, with the same parameters, should be applied to both. Otherwise, information of the training set can 'leak' into the testing process, while the testing stage needs to be completely independent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "To simplify this, we can set up a pipeline containing the various steps that need to be applied, i.e., transformation and training a classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit_time value: [0.00207186 0.00186396 0.00192285 0.00184631 0.00183868 0.00193381\n",
      " 0.00195336 0.00185204 0.00182962 0.00188851]\n",
      "score_time value: [0.00029707 0.00029182 0.00029445 0.00031281 0.00028801 0.00028872\n",
      " 0.00029397 0.00028563 0.0002861  0.00028586]\n",
      "test_accuracy value: [0.97183099 0.98591549 1.         1.         0.97183099 0.98550725\n",
      " 1.         0.98550725 0.98550725 1.        ]\n",
      "train_accuracy value: [0.99205087 0.99205087 0.99046105 0.99046105 0.99205087 0.99049128\n",
      " 0.9889065  0.99207607 0.99049128 0.9889065 ]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "metrics = ['accuracy']\n",
    "\n",
    "pipeline = make_pipeline(StandardScaler(), classifier)\n",
    "outcomes = cross_validate(pipeline, X_train, y_train, scoring=metrics, cv=10, return_train_score=True)\n",
    "for metric in outcomes.keys():\n",
    "    print(metric+\" value: \"+str(outcomes[metric]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions for every sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "If you want to obtain the predictions for every sample from when it was in the test set (in 10-fold CV, every sample is used exactly once), the following code can be used:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9885714285714285\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "predictions = cross_val_predict(pipeline, X_train, y_train, cv=10)\n",
    "print(accuracy_score(y_train, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "Typically, we will use cross-validation to see what classifier, or what parameters, are working best over our training/validation sets. Then, finally, we use them on our test set for our final evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding sampling strategy to pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "Since our data is imbalanced, we might want to preserve this imbalance in every fold. To do so, we can use the stratified CV procedure as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit_time value: [0.00200963 0.00181651 0.00188613 0.00185299 0.00185609 0.0019474\n",
      " 0.00192094 0.00187111 0.00183249 0.00187373]\n",
      "score_time value: [0.00029373 0.00028753 0.00028324 0.00028539 0.00028801 0.00028729\n",
      " 0.00028419 0.00028729 0.00028229 0.0002811 ]\n",
      "test_accuracy value: [0.97183099 0.98591549 1.         1.         0.97183099 0.98550725\n",
      " 1.         0.98550725 0.98550725 1.        ]\n",
      "train_accuracy value: [0.99205087 0.99205087 0.99046105 0.99046105 0.99205087 0.99049128\n",
      " 0.9889065  0.99207607 0.99049128 0.9889065 ]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "stratified_kfold = StratifiedKFold(n_splits=10, random_state=40)\n",
    "outcomes = cross_validate(pipeline, X_train, y_train, scoring=metrics, cv=stratified_kfold, return_train_score=True)\n",
    "for metric in outcomes.keys():\n",
    "    print(metric+\" value: \"+str(outcomes[metric]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 [3.6]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
