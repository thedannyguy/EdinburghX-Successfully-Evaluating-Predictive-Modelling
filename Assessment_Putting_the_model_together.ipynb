{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Putting everything together"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "Let's start by loading the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " False.    4293\n",
      " True.      707\n",
      "Name: Churn, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "np.random.seed(40)\n",
    "\n",
    "data = pd.read_csv(\"churn.csv\",sep=',',index_col=0)\n",
    "\n",
    "y = data['Churn']\n",
    "X = data.drop('Churn',axis=1)\n",
    "\n",
    "print(y.value_counts())\n",
    "#print(data.describe(include='all'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "def convert_and_remove_categorical_variables(X, to_convert, to_remove):\n",
    "    from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "    from pandas.api.types import is_numeric_dtype\n",
    "\n",
    "    for variable in X.columns:    \n",
    "        if variable in to_convert:\n",
    "            if len(X[variable].unique()) < 10:\n",
    "                X = pd.concat([X,pd.get_dummies(X[variable], prefix=variable, drop_first=True)],axis=1).drop([variable],axis=1)  \n",
    "        elif variable in to_remove:\n",
    "            X = X.drop([variable],axis=1)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "to_convert = ['Area_Code','International_Plan','Voice_mail_Plan']\n",
    "to_remove = ['Phone_Number']\n",
    "X = data.drop('Churn',axis=1)\n",
    "X = convert_and_remove_categorical_variables(X, to_convert, to_remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "encoder = LabelEncoder()    \n",
    "y = encoder.fit_transform(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the whole pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "Now, let's put everything together: make a function that again creates a cross-validation setup, and which also applies feature selection and other helpful pre-processing or feature generation techniques in its pipeline. More specifically, extend your code so that not only different models, but also different selection techniques, are used, as defined in the list below. Again, the stratified shuffling should be an option, and an extra parameter (select_best) is used for the feature selection techniques where necessary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": false,
     "grade_id": "evaluation_process",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression as LR\n",
    "from sklearn.tree import DecisionTreeClassifier as DT\n",
    "from sklearn.ensemble import RandomForestClassifier as RF\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    " \n",
    "def evaluation_process(X_train, y_train, classifier, n_fold, selection_technique, select_best, oversampling):\n",
    "    from sklearn.decomposition import PCA\n",
    "    from sklearn.linear_model import LogisticRegression as LR\n",
    "    from sklearn.tree import DecisionTreeClassifier as DT\n",
    "    from sklearn.ensemble import RandomForestClassifier as RF\n",
    "    from imblearn.pipeline import make_pipeline\n",
    "    from sklearn.preprocessing import Normalizer\n",
    "    from sklearn.model_selection import cross_validate\n",
    "    from sklearn.feature_selection import chi2, mutual_info_regression, mutual_info_classif\n",
    "    from sklearn.feature_selection import SelectKBest\n",
    "    from sklearn.model_selection import ShuffleSplit, KFold, StratifiedKFold\n",
    "    from sklearn.model_selection import train_test_split as tts\n",
    "    from sklearn.model_selection import StratifiedShuffleSplit\n",
    "    from imblearn.over_sampling import SMOTE\n",
    "\n",
    "    import warnings\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    stratifiedk_fold = StratifiedKFold(n_splits = n_fold)\n",
    "    metrics = ['accuracy','precision','roc_auc']\n",
    "    \n",
    "    accuracy = 0\n",
    "    precision = 0\n",
    "    auroc = 0\n",
    "    normalizer = Normalizer()\n",
    "    pipeline = make_pipeline(Normalizer())\n",
    "    if oversampling == True:\n",
    "        smt = SMOTE(random_state = 42)\n",
    "        pipeline.steps.append(('SMOTE', smt))\n",
    "        #pipeline.steps.append(('Normalizer', Normalizer()))\n",
    "           \n",
    "    if selection_technique == 'chi2': \n",
    "        pipeline.steps.append(('chi2', SelectKBest(chi2, k = select_best)))\n",
    "    elif selection_technique == 'mutual_information':\n",
    "        pipeline.steps.append(('mutual_information', SelectKBest(mutual_info_classif, k = select_best)))\n",
    "    elif selection_technique == 'PCA':\n",
    "        pipeline.steps.append(('PCA', PCA()))\n",
    "       \n",
    "    pipeline.steps.append(('classifier', classifier))\n",
    "    \n",
    "    outcomes = cross_validate(pipeline, X_train, y_train, scoring=metrics, cv=stratifiedk_fold, return_train_score=False)\n",
    "         \n",
    "    accuracy += (np.average(outcomes['test_accuracy']))\n",
    "    precision += (np.average(outcomes['test_precision']))\n",
    "    auroc += (np.average(outcomes['test_roc_auc']))\n",
    "                                                 \n",
    "    return accuracy, precision, auroc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.914, precision: 0.8413222662220161 AUC: 0.8660133333333334\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split as tts\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "np.random.seed(42)\n",
    "select_best = 2\n",
    "\n",
    "# Our training and test set:\n",
    "X_train, X_test, y_train, y_test = tts(X, y, test_size = 0.3)\n",
    "\n",
    "# Our parameters:\n",
    "models = [LR(), DT(), RF()]\n",
    "names = ['LogReg','DecTree','RandomFor']\n",
    "selection_techniques = ['None','PCA','chi2','mutual_information']\n",
    "\n",
    "best_mean = 0\n",
    "acc = []\n",
    "prec = []\n",
    "auro = []\n",
    "\n",
    "# Verify your result:\n",
    "accuracy, precision, auroc = evaluation_process(X_train, y_train, RF(), 10, 'mutual_information', 10, False) \n",
    "print('Accuracy '+str(accuracy)+\", precision: \"+str(precision)+\" AUC: \"+str(auroc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "verify_evaluation_process",
     "locked": true,
     "points": "15",
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
